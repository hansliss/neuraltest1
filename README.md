# Neural Glyph Recognizer

This project trains a small, fully-connected neural network (implemented in pure NumPy) to recognize printable Latin-1 characters rendered as 16×16 grayscale bitmaps. The training data is generated by rendering glyphs from the TrueType font files placed beneath the `fonts/` directory.

## Quick start

1. Create and activate the virtual environment, then install dependencies:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
2. Launch a training run (adjust ratios, batch sizes, etc. as needed):
   ```bash
   source venv/bin/activate
   python scripts/train.py \
       --fonts-dir fonts \
       --artifacts-dir artifacts \
       --cache-dir artifacts/cache \
       --epochs 20 \
       --batch-size 128 \
       --learning-rate 0.1 \
       --hidden-dim 512
   ```
   The script will split the available fonts into train/validation/test partitions, render glyphs into cached `.npz` datasets, train the classifier, evaluate it on the held-out test split, and persist the resulting model and metadata under `artifacts/run-<timestamp>/`.

## Using the trained model

- **Evaluate** the model on a cached split:
  ```bash
  source venv/bin/activate
  python scripts/evaluate.py \
      --model-dir artifacts/run-<timestamp> \
      --cache-dir artifacts/cache \
      --split test
  ```
- **Predict** the character encoded in a 16×16 grayscale image:
  ```bash
  source venv/bin/activate
  python scripts/predict.py \
      --model-dir artifacts/run-<timestamp> \
      --image path/to/bitmap.png \
      --top-k 5
  ```

The predictor automatically normalizes the bitmap, runs it through the trained network, and reports the most likely Latin-1 characters along with confidence scores.

## How it works

- `glyphnet/rendering.py` renders each printable Latin-1 character for a given font on an oversized canvas and downsamples it to 16×16 grayscale.
- `glyphnet/data/dataset.py` builds (and caches) datasets backed by NumPy arrays, where each sample is a flattened bitmap and its corresponding character label.
- `glyphnet/models/simple_nn.py` defines a compact two-layer neural network with ReLU activation and softmax output, implemented directly in NumPy for pedagogical clarity.
- `glyphnet/training.py` handles the training loop, including mini-batching, gradient clipping, early stopping, and accuracy tracking.
- `glyphnet/persistence.py` and `glyphnet/inference.py` cover saving/loading model artifacts and running inference on arbitrary bitmaps.

The character set currently targets the printable subset of Latin-1 (code points 32–126 and 160–255). Characters that a font cannot render are skipped during dataset generation so the training set only contains valid glyphs.

## Tips

- **Rendering cache**: The first training run can take some time because every glyph is rendered. Subsequent runs reuse the cached `.npz` files unless `--force-rebuild` is specified.
- **Experiment quickly**: Use `--max-fonts-train`, `--max-fonts-val`, and `--max-fonts-test` to limit the number of fonts for smoke tests.
- **Fresh runs**: Delete `artifacts/cache/` or pass `--force-rebuild` if you change the font lists or rendering parameters and want to rebuild datasets from scratch.

Feel free to explore the modules under `glyphnet/` to learn how each piece fits together. The code is intentionally modular so you can swap components (e.g., try a different model architecture or a more advanced optimizer) without touching the font rendering pipeline.
